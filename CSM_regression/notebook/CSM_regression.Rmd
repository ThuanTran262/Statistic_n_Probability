---
output:
  html_document: default
  pdf_document: default
---
```{r}
library("readxl")
library(corrplot)
library("dplyr")
library(mice, warn.conflicts=FALSE)
library(car)
library(caret)
library(dplyr)
library(cleandata)
```


[Data source](https://archive.ics.uci.edu/dataset/424/csm+conventional+and+social+media+movies+dataset+2014+and+2015)


# 1. EDA

```{r}
# Load data
data <- read_excel('../data/CSM.xlsx')
head(data)
```


```{r}
# Rename columns
colnames(data) = c("Movie", "Year", "Ratings", "Genre", "Gross", "Budget", "Screens", "Sequel", "Sentiment",
                   "Views", "Likes", "Dislikes", "Comments", "Aggregate_Followers")
```


```{r}
# data shape
nrow(data)
length(colnames(data))
```
The dataset has 231 rows and 12 columns


```{r}
# check the duplicated rows
nrow(unique(data))
```

The data shape does not change after de-duplicating, so there are no duplicated rows in the dataset


```{r}
# Check data type
str(data)
```
Comment:\

The dataset contains both quantitative and qualitative variables:
The qualitative variables: Genre, Sequel, Sentiment
The quantitative variables: The remains

We will exclude "Movie" and "Year" from model because they do not contribute to prediction.

```{r}
data <- data[, c('Ratings', 'Genre', 'Gross', 'Budget', 'Screens', 'Sequel', 'Sentiment', 'Views', 'Likes', 'Dislikes', 'Comments', 'Aggregate_Followers')]
```


Encoding qualitative variables:

```{r}
unique(data$Genre)
```

```{r}
unique(data$Sequel)
```

```{r}
unique(data$Sentiment)
```

Because Sequel and Sentiment is ordinal, we will apply Ordinal Encoding method for them. For Genre, we apply Dummy variables method.

```{r}
data$Genre = relevel(as.factor(data$Genre), ref=1)
```

```{r}
contrasts(data$Genre)
```

```{r}
data$Sentiment <- as.ordered(data$Sentiment)
data$Sequel <- as.ordered(data$Sequel)
```


# Check missing values (null values)

```{r}
colSums(is.na(data))/nrow(data)
```

15%, 4.3%, 0.43% is the missing percentage of of Aggregate_Followers, Screens and Budget respectively

## Missing data pattern

```{r, fig.height=9, fig.width=22}
md.pattern(data)
```

Comment:

- There are 187 (~80.95%) observations that are totally completed (no missing value in any column)\
- There are 33 (~14.28%) observations that have missing values at only column Aggregate Followers \
- There are 8 (~3.46%) observations that have missing values at only column Screens\
- There are 2 (~0.86%) observations that have missing values at both Aggregate_Followers and cá»™t Screens\
- There is only 1 (~0.43%) observation that have missing value at only column Budget\

Most data is missed in only 1 column.

The null percentage of Budget is very small (only 0.43%) so that we will remove this record from the dataset. For the Screens and Aggregate_Followers, we will fill missing data using "mice" algorithm

```{r}
# Remove 1 missing value at Budget
data <- subset(data, is.na(data$Budget) == FALSE)
```


```{r}
# "mice" algorithm using "cart" method
imp <- mice(data, method='cart', seed=123)
data_cpt <- complete(imp)
```

Compare mean before and after fill null, check whether their mean comes from same distribution or not.

Hypothesis:
H0: mu_before = mu_after
H1: mu_before!= mu_after

Choose anpha = 0.05

```{r}
# t-test for Screens
t.test(data$Screens, data_cpt$Screens)
```

With p-value = 0.6427, There is not enough clue to reject H0 => Conclusion: The mean of Screens before filled null and after filled null is the same.

```{r}
# t-test for Aggregate_Followers
t.test(data$Aggregate_Followers, data_cpt$Aggregate_Followers)
```
With p-value = 0.7459, There is not enough clue to reject H0 => Conclusion: The mean of Aggregate_Followers before filled null and after filled null is the same.


## Check the correlative between quantitative variables:

```{r, fig.height=8}
numeric_cols = c('Ratings', 'Budget', 'Screens', 'Views', 'Likes', 'Dislikes', 'Comments', 'Aggregate_Followers')
corrplot(cor(data_cpt[,numeric_cols]), addCoef.col = 'black', method="color")
```

With threshold 0.8, there is the high correlation between Comments and Likes. We will handle it later

# Check the distribution of quantitative variables:

```{r, fig.width=10}
numeric_cols = c('Ratings', 'Gross', 'Budget', 'Screens', 'Views', 'Likes', 'Dislikes', 'Comments', 'Aggregate_Followers')
par(mfrow=c(2, 5))
for (i in numeric_cols){
  hist(data_cpt[[i]], main=i)
}
```

Gross is high skew (not normal). In linear regression model, we assume that dependence variable have normal shape, so that we will apply Box-Cox transformation for Gross, which will change Gross's distribution to approximatetly normal.
Besides, the range of variables is different => need to be scaled.

```{r}
bc_trans <- BoxCoxTrans(data_cpt$Gross)
data_cpt$Gross <- predict(bc_trans, data_cpt$Gross)
```

```{r}
shapiro.test(data_cpt$Gross)
```


```{r}
lambda <- bc_trans$lambda
lambda
```


```{r}
par(mfrow=c(1, 2))
ggplot(data.frame(x = data_cpt$Gross), aes(x)) +
  geom_histogram(binwidth = 100, color = "black", fill = "lightblue") +
  ggtitle("Histogram of Box-Cox Transformed Data")
```


```{r}
qqnorm(data_cpt$Gross)
qqline(data_cpt$Gross, col = "red")
```



Scale data (mean = 0 and std = 1):


```{r}
std <- sd(data_cpt$Gross)
mu <- mean(data_cpt$Gross)
```


```{r}
numeric_cols = c('Ratings', 'Gross', 'Budget', 'Screens', 'Views', 'Likes', 'Dislikes', 'Comments', 'Aggregate_Followers')
for (i in numeric_cols){
  data_cpt[[i]] <- scale(data_cpt[[i]])
}
```


```{r, fig.width=10}
numeric_cols = c('Ratings', 'Gross', 'Budget', 'Screens', 'Views', 'Likes', 'Dislikes', 'Comments', 'Aggregate_Followers')
par(mfrow=c(2, 5))
for (i in numeric_cols){
  hist(data_cpt[[i]], main=i)
}
```


# Check outliers data

```{r, fig.width=10}
numeric_cols = c('Ratings', 'Gross', 'Budget', 'Screens', 'Views', 'Likes', 'Dislikes', 'Comments', 'Aggregate_Followers')
par(mfrow=c(2, 5))
for (i in numeric_cols){
  boxplot(data_cpt[[i]], xlab=i)
}
```


Except for Screens, outliers appear in all remaining variables.


# Detect outlier for multivariate variables using mahalanobis distance


```{r, fig.width=8}
pairs(data_cpt[,numeric_cols])
```

```{r}
MD <- mahalanobis(data_cpt[, numeric_cols], colMeans(data_cpt[, numeric_cols]), cov(data_cpt[, numeric_cols]), inverted=TRUE)
```

```{r}
data_cpt$MD <- MD
```

```{r}
boxplot(MD, main='Boxplot of Mahalanobis distance')
```


```{r}
quartiles <- quantile(data_cpt$MD, probs=c(.25, .75))
IQR <- IQR(data_cpt$MD)
Lower <- quartiles[1] - 1.5*IQR
Upper <- quartiles[2] + 1.5*IQR
```


```{r}
exclude_data <- subset(data_cpt, data_cpt$MD <= Lower | data_cpt$MD >= Upper)
mean(exclude_data$MD)
```


```{r}
data_cpt <- data_cpt %>% mutate(Group = case_when(MD > Lower & MD < Upper ~ 1,
                                       MD <= Lower | MD >= Upper ~ 2))
head(data_cpt)
```



```{r, fig.width=8}
numeric_cols = c('Ratings', 'Gross', 'Budget', 'Screens', 'Views', 'Likes', 'Dislikes', 'Comments', 'Aggregate_Followers')
Group <- data_cpt[, c('Group')]
l <- length(unique(Group))
pairs(data_cpt[,numeric_cols], bg = hcl.colors(l, "Temps")[Group], col = hcl.colors(l, "Temps")[Group])
```
Note: Red color represents for outlier points and will be remove from dataset, green color represents for the normal point.


```{r}
data_new <- subset(data_cpt, data_cpt$MD > Lower & data_cpt$MD < Upper)
```

```{r, fig.width=10}
numeric_cols = c('Ratings', 'Gross', 'Budget', 'Screens', 'Views', 'Likes', 'Dislikes', 'Comments', 'Aggregate_Followers')
par(mfrow=c(2, 5))
for (i in numeric_cols){
  boxplot(data_new[[i]], xlab=i)
}
```

```{r}
nrow(data_cpt)
nrow(data_new)
```

Only 6% data is removed.


```{r}
str(data_new)
```

 
 # Build model for prediction
 
 - Train test split:

 
```{r}
# Split train-test data
set.seed(123)
training.samples <- data_new$Gross  %>%  createDataPartition(p = 0.8, list = FALSE)
train.data  <- data_new[training.samples, ]
test.data <- data_new[-training.samples, ]
dim(train.data)
dim(test.data)
```

Build model to remove high correlation variables that cause "multicollinearity"


```{r}
df <- train.data[,c("Ratings", "Gross", "Budget", "Screens", "Views", "Likes",
                    "Dislikes", "Comments", "Aggregate_Followers")]
model_1 <- lm(Gross~., data=df)
vif_model_1 <- vif(model_1)
barplot(vif_model_1, col = "bisque1", main = "Variance Inflation Factor (VIF)", 
        las = 2, cex.names = 1)
```
 
```{r}
data.frame(vif_model_1)
```

The highest VIF is "Likes" (4.7, approximate 5) so that we will remove it from model


```{r}
model_2 <- lm(Gross~., data=df[, c("Ratings", "Gross", "Budget", "Screens", 
                                   "Comments", "Views", "Dislikes", "Aggregate_Followers")])
vif_model_2 <- vif(model_2)
barplot(vif_model_2, col = "bisque1", main = "Variance Inflation Factor (VIF)", 
        las = 2, cex.names = 1)
```

```{r}
data.frame(vif_model_2)
```

After remove "Likes", the remains variables have quite low VIF, we will keep it.

```{r}
# Build linear regression model
train.data <- train.data[, c("Ratings", "Gross", "Budget", "Screens", "Comments",
                             "Views", "Dislikes", "Aggregate_Followers", 'Genre', 
                             'Sequel', 'Sentiment')]
full_model <- lm(Gross~., data=train.data)
summary(full_model)
```

```{r}
# choose the best model using step wise method
step(full_model, direction = 'backward', trace = TRUE)
```
The best model (lowest AIC) is: Gross ~ Ratings + Budget + Screens + Dislikes + Aggregate_Followers

```{r}
model_re = lm(Gross~., data=train.data[,c('Gross', 'Ratings', 'Budget', 'Screens', 'Aggregate_Followers', 'Dislikes')])
summary(model_re)
```

The "Dislike" seems to have no effect to the change of "Gross" (p-value = 0.10403 > 0.05). Let's build other model without "Dislike".
Hypothesis:
H0: Accept shorten model (excluded "Dislike")
H1: Accept full model (included "Dislike")

```{r}
model_re_2 <- lm(Gross~., data=train.data[,c('Gross', 'Ratings', 'Budget', 'Screens', 'Aggregate_Followers')])
anova(model_re, model_re_2)
```

p-value = 0.104 > 0.05 so that we can not reject H0 => accept H0: Remove "Dislike"

```{r}
summary(model_re_2)
```
Predict step:

```{r}
# Make prediction
predictions <- model_re_2 %>% predict(test.data)
# Model performance
# (a) Prediction error, RMSE
rmse = RMSE(predictions, test.data$Gross)
rmse
```

```{r}
mu
std
```

```{r}
# inverse to value before scaling
inverse_pred <- predictions*std + mu
inverse_pred
```


```{r}
# inverse to value before scaling
inverse_actual <- test.data$Gross*std + mu
```


```{r}
rmse = RMSE(inverse_pred, inverse_actual)
rmse
```


```{r}
mean(inverse_actual)
```

```{r}
mean(inverse_pred)
```

```{r}
# inverse to value before Box-Cox transformation
bc_inv_pred <- exp(log(lambda * inverse_pred + 1) / lambda)
bc_inv_act <- exp(log(lambda * inverse_actual + 1) / lambda)
```


```{r}
RMSE(bc_inv_pred, bc_inv_act)
```

```{r}
mean(bc_inv_act)
```


```{r}
df <- data.frame(bc_inv_pred, bc_inv_act)
df
```

```{r}
df %>%  mutate(ID = 1:nrow(df)) %>%  ggplot(aes(ID)) +   
  geom_line(aes(y = bc_inv_pred, colour = "inverse_prediction")) + 
  geom_line(aes(y = bc_inv_act, colour = "inverse_actual"))
```



```{r}
data[68, 'Gross']
```
Shapiro-test for error's distribution (check if its distribution is Normal distribution or not)

```{r}
shapiro.test(residuals(model_re_2))
```
Hypothesis:
H0: e is normal distribution 
H1: e is not normal distribution
With p-value = 0.034, we will accept H0 if anpha < 0.03.

```{r}
plot(model_re_2)
```

